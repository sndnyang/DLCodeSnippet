{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as nfunc\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "gpu = \"\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "device = torch.device(\"cuda\" if gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_bn(bn, x, update_batch_stats=True):\n",
    "    if bn.training is False:\n",
    "        return bn(x)\n",
    "    elif not update_batch_stats:\n",
    "        return nfunc.batch_norm(x, None, None, bn.weight, bn.bias, True, bn.momentum, bn.eps)\n",
    "    else:\n",
    "        return bn(x)\n",
    "    \n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes, affine=False, top_bn=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_len = 1 * 28 * 28\n",
    "        self.fc1 = nn.Linear(self.input_len, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 1200)\n",
    "        self.fc3 = nn.Linear(1200, 10)\n",
    "\n",
    "        self.bn_fc1 = nn.BatchNorm1d(1200, affine=affine)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(1200, affine=affine)\n",
    "        self.top_bn = top_bn\n",
    "        if top_bn:\n",
    "            self.bn_fc3 = nn.BatchNorm1d(10, affine=affine)\n",
    "\n",
    "    def forward(self, x, update_batch_stats=True):\n",
    "        h = nfunc.relu(self.fc1(x.view(-1, self.input_len)))\n",
    "        h = self.fc2(h)\n",
    "        h = self.bn_fc2(h)\n",
    "        h = nfunc.relu(h)\n",
    "        h = self.fc3(h)\n",
    "        logits = h\n",
    "\n",
    "        return logits\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self, layer_sizes, affine=False, top_bn=True):\n",
    "        super(MLP2, self).__init__()\n",
    "        self.input_len = 1 * 28 * 28\n",
    "        self.fc1 = nn.Linear(self.input_len, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 1200)\n",
    "        self.fc3 = nn.Linear(1200, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x, update_batch_stats=True):\n",
    "        h = nfunc.relu(self.fc1(x.view(-1, self.input_len)))\n",
    "        h = self.fc2(h)\n",
    "        h = nfunc.relu(h)\n",
    "        h = self.fc3(h)\n",
    "        logits = h\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0.dev20190507'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "exp_marker = \"BoardTest/1\"\n",
    "base_dir = os.path.join(os.environ['HOME'], 'project/runs')\n",
    "dir_path = os.path.join(base_dir, exp_marker)\n",
    "if not os.path.isdir(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "writer = SummaryWriter(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalar(\"Test/acc\", 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0191,  0.0168,  0.0017,  0.0009,  0.0158,  0.0056,  0.0163, -0.0055,\n",
       "          0.0195,  0.0162],\n",
       "        [-0.0191,  0.0168,  0.0017,  0.0009,  0.0158,  0.0056,  0.0163, -0.0055,\n",
       "          0.0195,  0.0162]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(None)\n",
    "model(torch.zeros(2, 1, 28, 28))\n",
    "\n",
    "model = MLP2(None)\n",
    "model(torch.zeros(2, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:r ASSERT FAILED at /pytorch/aten/src/ATen/core/jit_type.h:142, please report a bug to PyTorch. (expect at /pytorch/aten/src/ATen/core/jit_type.h:142)\n",
      "frame #0: std::function<std::string ()>::operator()() const + 0x11 (0x7fe08c3da421 in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x2a (0x7fe08c3d9d5a in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libc10.so)\n",
      "frame #2: <unknown function> + 0x42e675 (0x7fe084799675 in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #3: <unknown function> + 0x131dfc (0x7fe08449cdfc in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "<omitting python frames>\n",
      "frame #26: <unknown function> + 0x1b0134 (0x7fe08451b134 in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #27: torch::jit::BlockToONNX(torch::jit::Block*, torch::jit::Block*, torch::onnx::OperatorExportTypes, std::unordered_map<torch::jit::Value*, torch::jit::Value*, std::hash<torch::jit::Value*>, std::equal_to<torch::jit::Value*>, std::allocator<std::pair<torch::jit::Value* const, torch::jit::Value*> > >) + 0x4c0 (0x7fe084770470 in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #28: torch::jit::ToONNX(std::shared_ptr<torch::jit::Graph>&, torch::onnx::OperatorExportTypes) + 0x3e6 (0x7fe084771616 in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #29: <unknown function> + 0x3fea79 (0x7fe084769a79 in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #30: <unknown function> + 0x131dfc (0x7fe08449cdfc in /home/xyang2/project/other/DLCodeSnippet/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(2, 1, 28, 28),\n",
      "      %1 : Float(1200, 784),\n",
      "      %2 : Float(1200),\n",
      "      %3 : Float(1200, 1200),\n",
      "      %4 : Float(1200),\n",
      "      %5 : Float(10, 1200),\n",
      "      %6 : Float(10),\n",
      "      %7 : Float(1200),\n",
      "      %8 : Float(1200),\n",
      "      %9 : Long(),\n",
      "      %10 : Float(1200),\n",
      "      %11 : Float(1200),\n",
      "      %12 : Long(),\n",
      "      %13 : Float(10),\n",
      "      %14 : Float(10),\n",
      "      %15 : Long()):\n",
      "  %57 : int[] = prim::Constant[value=[-1, 784]]()\n",
      "  %input.1 : Float(2, 784) = aten::view(%0, %57), scope: MLP\n",
      "  %36 : Float(784!, 1200!) = aten::t(%1), scope: MLP/Linear[fc1]\n",
      "  %58 : Long() = prim::Constant[value={1}](), scope: MLP/Linear[fc1]\n",
      "  %59 : Long() = prim::Constant[value={1}](), scope: MLP/Linear[fc1]\n",
      "  %39 : Float(2, 1200) = aten::addmm(%2, %input.1, %36, %58, %59), scope: MLP/Linear[fc1]\n",
      "  %input.2 : Float(2, 1200) = aten::relu(%39), scope: MLP\n",
      "  %41 : Float(1200!, 1200!) = aten::t(%3), scope: MLP/Linear[fc2]\n",
      "  %60 : Long() = prim::Constant[value={1}](), scope: MLP/Linear[fc2]\n",
      "  %61 : Long() = prim::Constant[value={1}](), scope: MLP/Linear[fc2]\n",
      "  %input.3 : Float(2, 1200) = aten::addmm(%4, %input.2, %41, %60, %61), scope: MLP/Linear[fc2]\n",
      "  %45 : Tensor? = prim::Constant(), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %46 : Tensor? = prim::Constant(), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %62 : Long() = prim::Constant[value={0}](), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %63 : Double() = prim::Constant[value={0.1}](), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %64 : Double() = prim::Constant[value={1e-05}](), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %65 : Long() = prim::Constant[value={1}](), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %h : Float(2, 1200) = aten::batch_norm(%input.3, %45, %46, %10, %11, %62, %63, %64, %65), scope: MLP/BatchNorm1d[bn_fc2]\n",
      "  %input : Float(2, 1200) = aten::relu(%h), scope: MLP\n",
      "  %53 : Float(1200!, 10!) = aten::t(%5), scope: MLP/Linear[fc3]\n",
      "  %66 : Long() = prim::Constant[value={1}](), scope: MLP/Linear[fc3]\n",
      "  %67 : Long() = prim::Constant[value={1}](), scope: MLP/Linear[fc3]\n",
      "  %56 : Float(2, 10) = aten::addmm(%6, %input, %53, %66, %67), scope: MLP/Linear[fc3]\n",
      "  return (%56)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_input = (torch.zeros(2, 1, 28, 28),)\n",
    "writer.add_graph(MLP(None), dummy_input, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0.dev20190507\n",
      "graph(%0 : Float(2, 1, 28, 28),\n",
      "      %1 : Float(1200, 784),\n",
      "      %2 : Float(1200),\n",
      "      %3 : Float(1200, 1200),\n",
      "      %4 : Float(1200),\n",
      "      %5 : Float(10, 1200),\n",
      "      %6 : Float(10)):\n",
      "  %7 : Tensor = onnx::Constant[value=  -1  784 [ Variable[CPUType]{2} ]](), scope: MLP2\n",
      "  %8 : Float(2, 784) = onnx::Reshape(%0, %7), scope: MLP2\n",
      "  %9 : Float(784!, 1200!) = onnx::Transpose[perm=[1, 0]](%1), scope: MLP2/Linear[fc1]\n",
      "  %10 : Float(2, 1200) = onnx::Gemm[alpha=1, beta=1](%8, %9, %2), scope: MLP2/Linear[fc1]\n",
      "  %11 : Float(2, 1200) = onnx::Relu(%10), scope: MLP2\n",
      "  %12 : Float(1200!, 1200!) = onnx::Transpose[perm=[1, 0]](%3), scope: MLP2/Linear[fc2]\n",
      "  %13 : Float(2, 1200) = onnx::Gemm[alpha=1, beta=1](%11, %12, %4), scope: MLP2/Linear[fc2]\n",
      "  %14 : Float(2, 1200) = onnx::Relu(%13), scope: MLP2\n",
      "  %15 : Float(1200!, 10!) = onnx::Transpose[perm=[1, 0]](%5), scope: MLP2/Linear[fc3]\n",
      "  %16 : Float(2, 10) = onnx::Gemm[alpha=1, beta=1](%14, %15, %6), scope: MLP2/Linear[fc3]\n",
      "  return (%16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "dummy_input = (torch.zeros(2, 1, 28, 28),)\n",
    "writer.add_graph(MLP2(None), dummy_input, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 3),\n",
      "      %1 : Float(5, 3),\n",
      "      %2 : Float(5)):\n",
      "  %3 : Float(3!, 5!) = onnx::Transpose[perm=[1, 0]](%1), scope: LinearInLinear/Linear[l]\n",
      "  %4 : Float(1, 5) = onnx::Gemm[alpha=1, beta=1](%input, %3, %2), scope: LinearInLinear/Linear[l]\n",
      "  return (%4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "dummy_input = (torch.zeros(1, 3),)\n",
    "\n",
    "class LinearInLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearInLinear, self).__init__()\n",
    "        self.l = nn.Linear(3, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l(x)\n",
    "    \n",
    "writer.add_graph(LinearInLinear(), dummy_input, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
